{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T07:43:16.046678300Z",
     "start_time": "2023-12-20T07:43:13.928665700Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from env.car_racing_wrapper import Env\n",
    "from rl_agents.PPO_on import PPO_on\n",
    "from rl_agents.rl_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-20T07:41:15.863283600Z",
     "start_time": "2023-12-20T07:41:11.092374600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]D:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "D:\\workspace\\RL\\CS138-Final-Project\\rl_agents\\rl_utils.py:161: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  return torch.tensor(advantage_list, dtype=torch.float)\n",
      "  1%|          | 1/100 [00:03<05:32,  3.36s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 18\u001B[0m\n\u001B[0;32m     15\u001B[0m action_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[0;32m     17\u001B[0m agent \u001B[38;5;241m=\u001B[39m PPO_on(input_channels, hidden_dim, action_dim, actor_lr, critic_lr, gamma, lmbda, ppo_epoch, eps)\n\u001B[1;32m---> 18\u001B[0m return_list, training_time \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_on_policy_agent_on\u001B[49m\u001B[43m(\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43magent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_episodes\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\workspace\\RL\\CS138-Final-Project\\rl_agents\\rl_utils.py:175\u001B[0m, in \u001B[0;36mtrain_on_policy_agent_on\u001B[1;34m(env, agent, num_episodes)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m done:\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;66;03m# print(type(state))\u001B[39;00m\n\u001B[0;32m    174\u001B[0m     action \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mtake_action(state)\n\u001B[1;32m--> 175\u001B[0m     next_state, reward, terminated, truncated \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransfer_action_shape\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    176\u001B[0m     done \u001B[38;5;241m=\u001B[39m terminated \u001B[38;5;129;01mor\u001B[39;00m truncated\n\u001B[0;32m    177\u001B[0m     transition_dict[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstates\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(state)\n",
      "File \u001B[1;32mD:\\workspace\\RL\\CS138-Final-Project\\env\\car_racing_wrapper.py:31\u001B[0m, in \u001B[0;36mEnv.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maction_repeat):\n\u001B[0;32m     30\u001B[0m     flag \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m---> 31\u001B[0m     img_rgb, reward, die, _, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;66;03m# don't penalize \"die state\"\u001B[39;00m\n\u001B[0;32m     33\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m die:\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001B[0m, in \u001B[0;36mTimeLimit.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, action):\n\u001B[0;32m     40\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001B[39;00m\n\u001B[0;32m     41\u001B[0m \n\u001B[0;32m     42\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     48\u001B[0m \n\u001B[0;32m     49\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 50\u001B[0m     observation, reward, terminated, truncated, info \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m     53\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_elapsed_steps \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_max_episode_steps:\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001B[0m, in \u001B[0;36mOrderEnforcing.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_reset:\n\u001B[0;32m     36\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m ResetNeeded(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot call env.step() before calling env.reset()\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001B[0m, in \u001B[0;36mPassiveEnvChecker.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m env_step_passive_checker(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39menv, action)\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 39\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43maction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:541\u001B[0m, in \u001B[0;36mCarRacing.step\u001B[1;34m(self, action)\u001B[0m\n\u001B[0;32m    538\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mworld\u001B[38;5;241m.\u001B[39mStep(\u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m FPS, \u001B[38;5;241m6\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m30\u001B[39m, \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m30\u001B[39m)\n\u001B[0;32m    539\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mt \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1.0\u001B[39m \u001B[38;5;241m/\u001B[39m FPS\n\u001B[1;32m--> 541\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_render\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstate_pixels\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    543\u001B[0m step_reward \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m    544\u001B[0m terminated \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:596\u001B[0m, in \u001B[0;36mCarRacing._render\u001B[1;34m(self, mode)\u001B[0m\n\u001B[0;32m    593\u001B[0m trans \u001B[38;5;241m=\u001B[39m pygame\u001B[38;5;241m.\u001B[39mmath\u001B[38;5;241m.\u001B[39mVector2((scroll_x, scroll_y))\u001B[38;5;241m.\u001B[39mrotate_rad(angle)\n\u001B[0;32m    594\u001B[0m trans \u001B[38;5;241m=\u001B[39m (WINDOW_W \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m+\u001B[39m trans[\u001B[38;5;241m0\u001B[39m], WINDOW_H \u001B[38;5;241m/\u001B[39m \u001B[38;5;241m4\u001B[39m \u001B[38;5;241m+\u001B[39m trans[\u001B[38;5;241m1\u001B[39m])\n\u001B[1;32m--> 596\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_render_road\u001B[49m\u001B[43m(\u001B[49m\u001B[43mzoom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mangle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    597\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcar\u001B[38;5;241m.\u001B[39mdraw(\n\u001B[0;32m    598\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msurf,\n\u001B[0;32m    599\u001B[0m     zoom,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    602\u001B[0m     mode \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_pixels_list\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstate_pixels\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m    603\u001B[0m )\n\u001B[0;32m    605\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msurf \u001B[38;5;241m=\u001B[39m pygame\u001B[38;5;241m.\u001B[39mtransform\u001B[38;5;241m.\u001B[39mflip(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msurf, \u001B[38;5;28;01mFalse\u001B[39;00m, \u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:658\u001B[0m, in \u001B[0;36mCarRacing._render_road\u001B[1;34m(self, zoom, translation, angle)\u001B[0m\n\u001B[0;32m    649\u001B[0m         grass\u001B[38;5;241m.\u001B[39mappend(\n\u001B[0;32m    650\u001B[0m             [\n\u001B[0;32m    651\u001B[0m                 (GRASS_DIM \u001B[38;5;241m*\u001B[39m x \u001B[38;5;241m+\u001B[39m GRASS_DIM, GRASS_DIM \u001B[38;5;241m*\u001B[39m y \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0\u001B[39m),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    655\u001B[0m             ]\n\u001B[0;32m    656\u001B[0m         )\n\u001B[0;32m    657\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m poly \u001B[38;5;129;01min\u001B[39;00m grass:\n\u001B[1;32m--> 658\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_colored_polygon\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    659\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msurf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoly\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgrass_color\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mzoom\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtranslation\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mangle\u001B[49m\n\u001B[0;32m    660\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    662\u001B[0m \u001B[38;5;66;03m# draw road\u001B[39;00m\n\u001B[0;32m    663\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m poly, color \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mroad_poly:\n\u001B[0;32m    664\u001B[0m     \u001B[38;5;66;03m# converting to pixel coordinates\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\cs138\\lib\\site-packages\\gym\\envs\\box2d\\car_racing.py:755\u001B[0m, in \u001B[0;36mCarRacing._draw_colored_polygon\u001B[1;34m(self, surface, poly, color, zoom, translation, angle, clip)\u001B[0m\n\u001B[0;32m    749\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m clip \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28many\u001B[39m(\n\u001B[0;32m    750\u001B[0m     (\u001B[38;5;241m-\u001B[39mMAX_SHAPE_DIM \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m coord[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m WINDOW_W \u001B[38;5;241m+\u001B[39m MAX_SHAPE_DIM)\n\u001B[0;32m    751\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m (\u001B[38;5;241m-\u001B[39mMAX_SHAPE_DIM \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m coord[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m WINDOW_H \u001B[38;5;241m+\u001B[39m MAX_SHAPE_DIM)\n\u001B[0;32m    752\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m coord \u001B[38;5;129;01min\u001B[39;00m poly\n\u001B[0;32m    753\u001B[0m ):\n\u001B[0;32m    754\u001B[0m     gfxdraw\u001B[38;5;241m.\u001B[39maapolygon(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msurf, poly, color)\n\u001B[1;32m--> 755\u001B[0m     \u001B[43mgfxdraw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfilled_polygon\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msurf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpoly\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolor\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "actor_lr = 1e-3\n",
    "critic_lr = 1e-3\n",
    "num_episodes = 100\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "lmbda = 0.95\n",
    "ppo_epoch = 10\n",
    "eps = 0.2\n",
    "\n",
    "env = Env(seed=0, action_repeat=8, img_stack=3,render_mode=None)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "input_channels = 3  \n",
    "action_dim = 10\n",
    "\n",
    "agent = PPO_on(input_channels, hidden_dim, action_dim, actor_lr, critic_lr, gamma, lmbda, ppo_epoch, eps)\n",
    "return_list, training_time = train_on_policy_agent_on(env, agent, num_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('./PPO_on_return_list.csv', 'w+') as file:\n",
    "    for i in range(len(return_list)):\n",
    "        file.write(str(return_list[i]) + \"\\n\")\n",
    "with open('./PPO_on_time.csv', 'w+') as file:\n",
    "        file.write(str(training_time) + \"\\n\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes_list = list(range(len(return_list)))\n",
    "plt.plot(episodes_list, return_list)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('PPO_on on {}'.format(\"CarRacing-v2\"))\n",
    "plt.savefig(\"figure1.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "mv_return = moving_average(return_list, 9)\n",
    "plt.plot(episodes_list, mv_return)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('PPO_on on {}'.format(\"CarRacing-v2\"))\n",
    "plt.savefig(\"figure2.png\", dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 8\u001B[0m\n\u001B[0;32m      5\u001B[0m hidden_dim \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m128\u001B[39m\n\u001B[0;32m      6\u001B[0m gamma \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.98\u001B[39m\n\u001B[1;32m----> 8\u001B[0m env \u001B[38;5;241m=\u001B[39m \u001B[43mEnv\u001B[49m(seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, action_repeat\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m8\u001B[39m, img_stack\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, render_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhuman\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m torch\u001B[38;5;241m.\u001B[39mmanual_seed(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     12\u001B[0m agent \u001B[38;5;241m=\u001B[39m PPO_on(input_channels, hidden_dim, action_dim, actor_lr, critic_lr, gamma)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'Env' is not defined"
     ]
    }
   ],
   "source": [
    "actor_lr = 1e-3\n",
    "critic_lr = 1e-2\n",
    "input_channels = 3  \n",
    "action_dim = 10\n",
    "hidden_dim = 128\n",
    "gamma = 0.98\n",
    "\n",
    "env = Env(seed=0, action_repeat=8, img_stack=3, render_mode=\"human\")\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "agent = PPO_on(input_channels, hidden_dim, action_dim, actor_lr, critic_lr, gamma)\n",
    "\n",
    "# 加载权重\n",
    "actor_weights_path = './weights/actor_weights.pth'\n",
    "critic_weights_path = './weights/critic_weights.pth'\n",
    "agent.load_weights(actor_weights_path, critic_weights_path)\n",
    "\n",
    "# 播放游戏\n",
    "play_game(env, agent, episodes=10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T07:40:56.123008200Z",
     "start_time": "2023-12-20T07:40:55.885977400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "cs138",
   "language": "python",
   "display_name": "cs138"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
